{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/owenmk/ok_cars/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRgTj35npSxs"
      },
      "source": [
        "# Cars Dataset\n",
        "Exploring the importance of size for supervised learning\n",
        "### reference\n",
        "[1] 3D Object Representations for Fine-Grained Categorization\n",
        "Jonathan Krause, Michael Stark, Jia Deng, Li Fei-Fei\n",
        "4th IEEE Workshop on 3D Representation and Recognition, at ICCV 2013 (3dRR-13). Sydney, Australia. Dec. 8, 2013."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wj6iS_3qpSxw"
      },
      "source": [
        "###  imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import List\n",
        "import torchvision.datasets.stanford_cars as stanford_cars\n",
        "from torchvision import datasets, io, models, ops, transforms, utils\n",
        "import pandas as pd\n",
        "import scipy.io\n",
        "import logging\n",
        "import os\n",
        "\n",
        "# create logger\n",
        "logger = logging.getLogger(__name__)\n",
        "# set log level for all handlers to debug\n",
        "logger.setLevel(logging.DEBUG)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## The Cars Dataset can be found here: (https://ai.stanford.edu/~jkrause/cars/car_dataset.html). \n",
        "# Data from reference [1] has been copied to an accessible filepath.\n",
        "\n",
        "NUM_IMAGE = 16185\n",
        "\"\"\"The dataset contains 16185 images. Here numbered with idx = 0, 1, ...\"\"\"\n",
        "\n",
        "IMG_PATH = '/mnt/c/Users/Owen/Documents/img_data/'\n",
        "\"\"\"Data from reference [1] has been copied to an accessible filepath.\"\"\"\n",
        "\n",
        "# Make image data available in the notebook\n",
        "#\n",
        "# transform = transforms.Compose([transforms.Resize(255),\n",
        "#                                 transforms.CenterCrop(224),\n",
        "#                                 transforms.ToTensor()])\n",
        "transform = transforms.ToTensor()\n",
        "dataset = datasets.ImageFolder(IMG_PATH, transform=transform)\n",
        "\n",
        "# Obtain train/test split and other annotations from the original author\n",
        "mat = scipy.io.loadmat(IMG_PATH +\"cars_annos.mat\")\n",
        "annotations = pd.DataFrame(mat['annotations'][0])\n",
        "annotations['class2']=[c[0,0] for c in annotations['class'].values] # manage indexing\n",
        "annotations['test2']=[c[0,0] for c in annotations['test'].values] # manage indexing\n",
        "annotations['relative_im_path2']=[c[0] for c in annotations['relative_im_path'].values] # manage indexing\n",
        "assert annotations.shape[0]==NUM_IMAGE, \"annotation problem\"\n",
        "annotations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Masking labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mask_labels(dataset_labels: List, proportion: float)->pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Remove a subset of labels from samples. Ensure each class has at least one labeled sample.\n",
        "    To remove 10% of labels, use proportion=0.1.\n",
        "    dataset_labels is a list of labels in sample order such that dataset_labels[0] is the label of the first sample and there are no gaps.\n",
        "    \"\"\"\n",
        "    # Cons\n",
        "    df = pd.DataFrame(data={'orig_label':dataset_label_list,'label':None})\n",
        "    df.index.name = 'idx'\n",
        "    num_samples = df.shape[0]\n",
        "\n",
        "    # Select samples to guarantee one from each class\n",
        "    keep_df = df.groupby('orig_label').apply(pd.DataFrame.sample, n=1)\n",
        "    keep_df = keep_df.reset_index('idx').reset_index(drop=True)\n",
        "    num_classes = keep_df.shape[0]\n",
        "\n",
        "    # How many samples to keep, in addition to 1 per class. Select them.\n",
        "    max_drop_frac = 1 - (num_classes / num_samples)\n",
        "    assert proportion <= max_drop_frac, f\"proportion must be less than {max_drop_frac}\"\n",
        "    num_new_keep = num_samples - num_classes - int(proportion*num_samples)\n",
        "    choose_from_idx = list(set(df.index) - set(keep_df['idx']))\n",
        "    new_keep_df = df.loc[choose_from_idx,:].sample(n=num_new_keep)\n",
        "\n",
        "    # For the ist of all sample indices to keep, transfer the known label\n",
        "    keep_idx = list(keep_df['idx']) + list(new_keep_df.index)\n",
        "    df.loc[keep_idx,'label'] = df.loc[keep_idx,'orig_label']\n",
        "    \n",
        "    return df\n",
        "# Example:\n",
        "dataset_label_list = annotations['class2'].tolist()\n",
        "proportion = 0.3\n",
        "label_df = mask_labels(dataset_label_list, proportion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data cleaning\n",
        "Find and delete any images that do not have 3 channels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def is_3chan_image(tensor_size)->bool:\n",
        "    \"\"\"utility returns True for 3-channel images\"\"\"\n",
        "    # TODO: confirm functionality using synthesize bw image: transform = transforms.Grayscale()\n",
        "    num_chanels = tensor_size[0]\n",
        "    result = num_chanels == 3 \n",
        "    return result\n",
        "\n",
        "def delete_image(imgpath: str):\n",
        "    logger.info(f\"Deleting image {imgpath}\")\n",
        "    try:\n",
        "        # os.remove(imgpath)\n",
        "        logger.info(f\"Removing sample {imgpath}\")\n",
        "    except OSError as e:\n",
        "        logger.error(f\"Error {e}\")\n",
        "        raise\n",
        "\n",
        "# Scan the dataset to confirm all 3 channels are present in each image\n",
        "logger.info(\"Check all images have 3 channels...\")\n",
        "image_sizes = {}\n",
        "num_deleted = 0\n",
        "for k in range(NUM_IMAGE):\n",
        "    sample_img, _ = dataset[k]\n",
        "    # num_chan = sample_img.size()[0]\n",
        "    if k % 1000 == 0: logger.info(f\"images checked: {k}\")\n",
        "    sample_image_size = sample_img.size()\n",
        "    if not is_3chan_image(sample_image_size):\n",
        "        print(f\"non standard image {k}: size {sample_image_size}, _ {_}\")\n",
        "        img_path = IMG_PATH + annotations.loc[k,'relative_im_path2']\n",
        "        delete_image(img_path)\n",
        "        num_deleted += 1\n",
        "    image_sizes[k] = sample_image_size\n",
        "logger.info(f\"Number of images deleted / scanned: {num_deleted}/{NUM_IMAGE}\")\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Dataset representation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_rep = {k:{'embedding':None,'class_idx':None, 'labelled': None} for k in range(NUM_IMAGE)}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Development continues..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "transform = transforms.Grayscale()\n",
        "img = transform(sample_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "help(stanford_cars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.15 ('ok_cars')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "1d539626c73eb7a50bfddad0f9ffed477fdd81d467a59e945260fdd9461201d4"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
